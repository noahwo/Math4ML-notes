---
dg-publish: true
dg-home:
---
A day-by-day curriculum that covers chapters 2-12 over a period of approximately 40 days. The plan will include reading assignments, exercises, and review days.

### Week 1: Linear Algebra

**Day 1**
- **Read**: Chapter 2 - "Systems of Linear Equations" and "Matrices"
- **Task**: Solve 2-3 example problems from each section

**Day 2**
- **Read**: Chapter 2 - "Solving Systems of Linear Equations" and "Vector Spaces"
- **Task**: Complete exercises 2.1 and 2.2

**Day 3**
- **Read**: Chapter 2 - "Linear Independence" and "Basis and Rank"
- **Task**: Complete exercises 2.3 and 2.4

**Day 4**
- **Read**: Chapter 2 - "Linear Mappings" and "Affine Spaces"
- **Task**: Complete exercises 2.5 and 2.6

**Day 5**
- **Review**: Chapter 2
- **Task**: Solve any remaining exercises from Chapter 2

**Day 6**
- **Read**: Chapter 3 - "Norms" and "Inner Products"
- **Task**: Complete exercise 3.1

**Day 7**
- Rest day / Catch-up

### Week 2: Analytic Geometry and Matrix Decompositions

**Day 8**
- **Read**: Chapter 3 - "Lengths and Distances" and "Angles and Orthogonality"
- **Task**: Complete exercises 3.2 and 3.3

**Day 9**
- **Read**: Chapter 3 - "Orthonormal Basis" and "Orthogonal Complement"
- **Task**: Complete exercises 3.4 and 3.5

**Day 10**
- **Read**: Chapter 3 - "Inner Product of Functions" and "Orthogonal Projections"
- **Task**: Complete exercise 3.6

**Day 11**
- **Read**: Chapter 3 - "Rotations"
- **Review**: Chapter 3
- **Task**: Complete any remaining exercises from Chapter 3

**Day 12**
- **Read**: Chapter 4 - "Determinant and Trace" and "Eigenvalues and Eigenvectors"
- **Task**: Complete exercises 4.1 and 4.2

**Day 13**
- **Read**: Chapter 4 - "Cholesky Decomposition" and "Eigendecomposition and Diagonalization"
- **Task**: Complete exercises 4.3 and 4.4

**Day 14**
- Rest day / Catch-up

### Week 3: Matrix Decompositions and Vector Calculus

**Day 15**
- **Read**: Chapter 4 - "Singular Value Decomposition" and "Matrix Approximation"
- **Task**: Complete exercises 4.5 and 4.6

**Day 16**
- **Read**: Chapter 4 - "Matrix Phylogeny"
- **Review**: Chapter 4
- **Task**: Complete any remaining exercises from Chapter 4

**Day 17**
- **Read**: Chapter 5 - "Differentiation of Univariate Functions" and "Partial Differentiation and Gradients"
- **Task**: Complete exercises 5.1 and 5.2

**Day 18**
- **Read**: Chapter 5 - "Gradients of Vector-Valued Functions" and "Gradients of Matrices"
- **Task**: Complete exercises 5.3 and 5.4

**Day 19**
- **Read**: Chapter 5 - "Useful Identities for Computing Gradients" and "Backpropagation and Automatic Differentiation"
- **Task**: Complete exercise 5.5

**Day 20**
- **Read**: Chapter 5 - "Higher-Order Derivatives" and "Linearization and Multivariate Taylor Series"
- **Task**: Complete exercises 5.6 and 5.7

**Day 21**
- Rest day / Catch-up

### Week 4: Probability and Distributions

**Day 22**
- **Read**: Chapter 6 - "Construction of a Probability Space" and "Discrete and Continuous Probabilities"
- **Task**: Complete exercises 6.1 and 6.2

**Day 23**
- **Read**: Chapter 6 - "Sum Rule, Product Rule, and Bayes' Theorem" and "Summary Statistics and Independence"
- **Task**: Complete exercises 6.3 and 6.4

**Day 24**
- **Read**: Chapter 6 - "Gaussian Distribution"
- **Task**: Complete exercise 6.5

**Day 25**
- **Read**: Chapter 6 - "Conjugacy and the Exponential Family" and "Change of Variables/Inverse Transform"
- **Task**: Complete exercises 6.6 and 6.7

**Day 26**
- **Review**: Chapter 6
- **Task**: Solve any remaining exercises from Chapter 6

**Day 27**
- **Read**: Chapter 7 - "Optimization Using Gradient Descent" and "Constrained Optimization and Lagrange Multipliers"
- **Task**: Complete exercises 7.1 and 7.2

**Day 28**
- Rest day / Catch-up

### Week 5: Continuous Optimization and Models Meet Data

**Day 29**
- **Read**: Chapter 7 - "Convex Optimization"
- **Review**: Chapter 7
- **Task**: Complete any remaining exercises from Chapter 7

**Day 30**
- **Read**: Chapter 8 - "Data, Models, and Learning" and "Empirical Risk Minimization"
- **Task**: Summarize key concepts from these sections

**Day 31**
- **Read**: Chapter 8 - "Parameter Estimation" and "Probabilistic Modeling and Inference"
- **Task**: Create a mind map of the relationships between different estimation methods

**Day 32**
- **Read**: Chapter 8 - "Directed Graphical Models" and "Model Selection"
- **Task**: Draw examples of directed graphical models for common machine learning problems

**Day 33**
- **Review**: Chapter 8
- **Task**: Write a brief essay on the importance of model selection in machine learning

**Day 34**
- **Read**: Chapter 9 - "Problem Formulation" and "Parameter Estimation"
- **Task**: Implement a simple linear regression model using the concepts learned

**Day 35**
- Rest day / Catch-up

### Week 6: Linear Regression, PCA, and GMM

**Day 36**
- **Read**: Chapter 9 - "Bayesian Linear Regression" and "Maximum Likelihood as Orthogonal Projection"
- **Task**: Compare and contrast frequentist and Bayesian approaches to linear regression

**Day 37**
- **Read**: Chapter 10 - "Maximum Variance Perspective" and "Projection Perspective"
- **Task**: Implement PCA on a small dataset and visualize the results

**Day 38**
- **Read**: Chapter 10 - "Eigenvector Computation and Low-Rank Approximations" and "PCA in High Dimensions"
- **Task**: Experiment with different numbers of principal components and observe the effect on reconstruction error

**Day 39**
- **Read**: Chapter 10 - "Latent Variable Perspective"
- **Review**: Chapter 10
- **Task**: Write a summary of the different perspectives on PCA

**Day 40**
- **Read**: Chapter 11 - "Gaussian Mixture Model" and "Parameter Learning via Maximum Likelihood"
- **Task**: Implement a simple Gaussian Mixture Model using the EM algorithm

### Week 7: GMM and SVM (Final Days)

**Day 41**
- **Read**: Chapter 11 - "Expectation Maximization" and "Latent-Variable Perspective"
- **Review**: Chapter 11
- **Task**: Apply GMM to a clustering problem and visualize the results

**Day 42**
- **Read**: Chapter 12 - "Separating Hyperplanes" and "Primal Support Vector Machine"
- **Task**: Implement a linear SVM classifier on a small dataset

**Day 43**
- **Read**: Chapter 12 - "Dual Support Vector Machine" and "Kernels"
- **Task**: Experiment with different kernels in SVM and observe their effects on classification boundaries

**Day 44**
- **Read**: Chapter 12 - "Numerical Solution"
- **Review**: Chapter 12
- **Task**: Compare the performance of SVM with other classification algorithms on a benchmark dataset

**Day 45**
- Final review and synthesis of all chapters
- Reflect on the journey and identify areas for further study

This study plan covers chapters 2-12 of "Mathematics for Machine Learning" over a period of 45 days, allowing for some flexibility and rest days. The plan includes daily reading assignments, tasks, and exercises to reinforce learning. Remember to adjust the pace as needed based on your progress and understanding of the material.